{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# builtins.__dict__.update(locals())\n",
    "# t = timeit.Timer('conved = list(map(lambda x: list(map(lambda y: y.value[0], x)), prevObs))')\n",
    "# time = t.timeit(10000)\n",
    "# print(time / 10000)\n",
    "import faulthandler\n",
    "import multiprocessing\n",
    "# logger = open('log.txt', 'w')\n",
    "# faulthandler.enable(file=logger)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, BatchNormalization, LeakyReLU, Add, Flatten, Dense, Concatenate, Dot, Reshape\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "# tf.autograph.set_verbosity(10,alsologtostdout=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "import gym_battleship1\n",
    "\n",
    "import builtins\n",
    "# import timeit # DEBUG Only\n",
    "import time\n",
    "# from collections import deques\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MODEL TWEAKS\n",
    "NUM_GAMES = 5100\n",
    "FILTERS = 64 # 64 because its cool\n",
    "EPSILON = 0.0 # Epsilon must start close to one or model training will scew incredibelly\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.1\n",
    "CHANNEL_TYPE = \"channels_first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayerCluster(inp):\n",
    "\tm = Conv2D(filters=FILTERS,kernel_size=(3,3),padding=\"same\",use_bias=False,activation='linear',kernel_regularizer=reg,data_format=CHANNEL_TYPE)(inp)\n",
    "\tm = BatchNormalization(axis=1)(m)\n",
    "\treturn LeakyReLU()(m)\n",
    "\n",
    "def residualLayerCluster(inp):\n",
    "\tm = convLayerCluster(inp)\n",
    "\tm = Conv2D(filters=FILTERS,kernel_size=(3,3),padding=\"same\",use_bias=False,activation='linear',kernel_regularizer=reg,data_format=CHANNEL_TYPE)(m)\n",
    "\tm = BatchNormalization(axis=1)(m)\n",
    "\tm = Add()([inp,m])\n",
    "\treturn LeakyReLU()(m)\n",
    "\n",
    "# @tf.function\n",
    "def customLoss(y_true, y_pred):\n",
    "\tcrossEnt = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
    "\treturn tf.reduce_mean(crossEnt)\n",
    "\n",
    "# def softmax_cross_entropy_with_logits(y_true, y_pred):\n",
    "\n",
    "#BUILDING MODEL\n",
    "# reg = tf.keras.regularizers.L2(l2=0.0001)\n",
    "reg = None # see if no reg helps \n",
    "def buildModel():\n",
    "\tinputLay = tf.keras.Input(shape=(6,10,10))#12\n",
    "\n",
    "\tm = Conv2D(filters=FILTERS,kernel_size=(3,3),padding=\"same\",use_bias=False,activation='linear',kernel_regularizer=reg,data_format=CHANNEL_TYPE)(inputLay)\n",
    "\t# m = Conv2D(64,3,data_format=CHANNEL_TYPE)(inputLay)\n",
    "\tm = BatchNormalization(axis=1)(m) #-1 for channels last\n",
    "\tm = LeakyReLU()(m)\n",
    "\n",
    "\tm = residualLayerCluster(m)\n",
    "\tm = residualLayerCluster(m)\n",
    "\t# m = residualLayerCluster(m) # removed on cluster for added simplricity\n",
    "\n",
    "\tm = Conv2D(filters=6,kernel_size=(1,1),padding=\"same\",use_bias=False,activation='linear',kernel_regularizer=reg,data_format=CHANNEL_TYPE)(m) #12\n",
    "\tm = BatchNormalization(axis=1)(m)\n",
    "\tm = LeakyReLU()(m)\n",
    "\n",
    "\tm = Flatten()(m)\n",
    "\tog = Flatten()(inputLay)\n",
    "\tr = Concatenate(axis=1)([m,og])\n",
    "\tout = Dense(100)(r) #activation='sigmoid'\n",
    "\n",
    "\treturn tf.keras.Model(inputs=inputLay, outputs=out)\n",
    "\n",
    "def oldBuildModel():\n",
    "\tinputLay = tf.keras.Input(shape=(6,10,10))\n",
    "\tc1 = Conv2D(1, (1, 1), data_format=\"channels_first\")(inputLay)\n",
    "\tc2 = Conv2D(1, (1, 1), data_format=\"channels_first\")(inputLay)\n",
    "\tf1 = Reshape((1,100))(c1)\n",
    "\tf2 = Reshape((1,100))(c2)\n",
    "\td = Dot(axes=1)([f1,f2])\n",
    "\tf3 = Flatten(data_format=\"channels_first\")(d)\n",
    "\t# inputLay = InputLayer(input_shape=(10,10,6))\n",
    "\t# out = Conv2D\n",
    "\tout = Dense(100)(f3) #INCLUDE\n",
    "\treturn tf.keras.Model(inputs=inputLay, outputs=out)\n",
    "\n",
    "model = buildModel()\n",
    "# model = tf.keras.models.load_model('saved_model/my_model',compile=False)\n",
    "\n",
    "# lossFunc = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optim = tf.keras.optimizers.SGD(lr=LEARNING_RATE, momentum = MOMENTUM) # optim = tf.keras.optimizers.SGD(lr=LEARNING_RATE, momentum = MOMENTUM)\n",
    "error = tf.keras.metrics.MeanAbsoluteError()\n",
    "lossAvg = tf.keras.metrics.Mean()\n",
    "# error = tf.keras.metrics.Mean()\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "gameLength = tf.keras.metrics.Mean()\n",
    "model.compile(optimizer=optim,loss=customLoss,metrics=[error,accuracy])\n",
    "summary_writer = tf.summary.create_file_writer('logs')\n",
    "print(model.summary())\n",
    "# model.load_weights('saved_model/checkpoints/cp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "ct = time.time()\n",
    "env = gym.make('battleship1-v1')\n",
    "\n",
    "@tf.function # Decoration is 10 fold faster\n",
    "def makeMove(obs,e):\n",
    "\t# print(\"Traced with \" + str(e))\n",
    "\tif e > 0:\n",
    "\t\tr = tf.random.uniform(shape=[],dtype=tf.dtypes.float16)\n",
    "\t\tif r < EPSILON:\n",
    "\t\t\treturn tf.random.uniform(shape=[],maxval=100,dtype=tf.dtypes.int64)\n",
    "\t\telse:\n",
    "\t\t\tlogits = model.predict_step(obs)\n",
    "\t\t\treturn tf.argmax(logits, 1)[0]\n",
    "\tlogits = model.predict_step(obs)\n",
    "\treturn tf.argmax(logits, 1)[0]\n",
    "\n",
    "@tf.function\n",
    "def trainGrads(feature,expect):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\t# predictions = self.model(features)\n",
    "\t\tlogits = model(feature,training=True)\n",
    "\t\tloss = customLoss(expect, logits[0])\n",
    "\t\t# loss = lossFunc(expect, predictions[0])\n",
    "\tgradients = tape.gradient(loss, model.trainable_variables)\n",
    "\toptim.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\terror.update_state(expect, logits[0])\n",
    "\taccuracy.update_state(expect, logits)\n",
    "\tlossAvg.update_state(loss)\n",
    "\treturn gradients\n",
    "\n",
    "# def singleStepConv():\n",
    "hits = 0\n",
    "iterartions = 0\n",
    "# sess = tf.Session()\n",
    "for epoch in range(0,NUM_GAMES):\n",
    "\tprevObs = env.reset()\n",
    "\tprevObs = [[[x.value[0] for x in y] for y in c] for c in prevObs] # redo timeit with numpy\n",
    "\t# prevObs = tf.reshape(tf.transpose(tf.convert_to_tensor(prevObs)),shape=(1,10,10,6)) # ONLY NEEDED FOR CPUS\n",
    "\tprevObs = tf.convert_to_tensor([prevObs])\n",
    "\t# prevObs = tf.reshape(prevObs, (1,10,10,6))\n",
    "\n",
    "\tobservations = [] # could also use deque\n",
    "\texpecteds = []\n",
    "\tdone = False\n",
    "\n",
    "\tslotsLeft = np.ones(shape=100,dtype=np.float32)\n",
    "\twhile not done:\n",
    "\t\t# Could Accelerate this, however few tf methods, and a couple of outside methods\n",
    "\t\tmove = makeMove(prevObs,EPSILON).numpy()\n",
    "\t\t# print(move.numpy())\n",
    "\t\tobs, reward, done, out = env.step(move)\n",
    "\t\tobs = [[[x.value[0] for x in y] for y in c] for c in obs] # numpy may be faster\n",
    "\t\tout = [t.value[0] for t in out]\n",
    "\n",
    "\t\t# out = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "\t\tif reward:\n",
    "\t\t\thits += 1\n",
    "\t\t# \tout[move].assign(1.)\n",
    "\t\t# \tobservations.append(prevObs[0])\n",
    "\t\t# \texpecteds.append(out)\n",
    "\t\t# elif done:\n",
    "\t\t# \tobservations.append(prevObs[0])\n",
    "\t\t# \texpecteds.append(tf.cast(tf.convert_to_tensor(out),dtype=tf.dtypes.float32))\n",
    "\n",
    "\t\tobservations.append(prevObs[0])\n",
    "\t\texpecteds.append(tf.convert_to_tensor(slotsLeft))\n",
    "\t\tslotsLeft[move] = 0\n",
    "\t\t# expecteds.append(tf.cast(tf.convert_to_tensor(out),dtype=tf.dtypes.float32))\n",
    "\n",
    "\t\tprevObs = tf.convert_to_tensor([obs])\n",
    "\t\t# prevObs = tf.reshape(tf.transpose(tf.convert_to_tensor(prevObs)),shape=(1,10,10,6))\n",
    "\t\titerartions += 1\n",
    "\t\tif done:\n",
    "\t\t\tgameLength.update_state(env.counter)\n",
    "\n",
    "\t# TRAINING\n",
    "\n",
    "\t# for i in range(len(observations)): # FOR DEBUGGING #\n",
    "\t# \tret = trainGrads(tf.reshape(observations[i],shape=(1,10,10,6)),expecteds[i])\n",
    "\t# \tpass\n",
    "\t\n",
    "\tobservations = tf.stack(observations)\n",
    "\texpecteds = tf.stack(expecteds)\n",
    "\tret = model.train_on_batch(x=observations,y=expecteds,reset_metrics=False,return_dict=True)\n",
    "\tlossAvg.update_state(ret['loss'])\n",
    "\n",
    "\tif (epoch+1) % (NUM_GAMES // 30) == 0:\n",
    "\t\twith summary_writer.as_default():\n",
    "\t\t\ttf.summary.scalar('Loss', lossAvg.result(), step=epoch+1)\n",
    "\t\t\ttf.summary.scalar('Error', error.result(), step=epoch+1)\n",
    "\t\t\ttf.summary.scalar('Accuracy', accuracy.result()*100, step=epoch+1)\n",
    "\t\t\ttf.summary.scalar('Hits', 100*hits / iterartions, step=epoch+1)\n",
    "\t\t\ttf.summary.scalar('Game Length', gameLength.result(), step=epoch+1)\n",
    "\t\tprint(f\"Completed {epoch+1} epochs at {round(EPSILON,7)} in {round(time.time() - ct, 3)}s. L={round(float(lossAvg.result().numpy()),6)} E={round(float(error.result().numpy()),6)} A={round(float(accuracy.result().numpy()),6)} H={round(hits / iterartions,6)} I={round(float(gameLength.result().numpy()),3)}\")\n",
    "\t\terror.reset_states()\n",
    "\t\taccuracy.reset_states()\n",
    "\t\tgameLength.reset_states()\n",
    "\t\tlossAvg.reset_states()\n",
    "\t\thits = 0\n",
    "\t\titerartions = 0\n",
    "\t\tif EPSILON > 0.06:\n",
    "\t\t\tEPSILON -= 0.03\n",
    "\t\telse:\n",
    "\t\t\tEPSILON /= 1.75\n",
    "\t\t# model.save_weights('saved_model/checkpoints/cp')\n",
    "\t\tct = time.time()\n",
    "\t\t# x = tf.function(makeMove)\n",
    "\n",
    "model.save('saved_model/my_model')\n",
    "print(\"Model Saved\")"
   ]
  }
 ]
}