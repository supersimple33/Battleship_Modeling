# Battleship_Modeling
## Premise
The original version of this project simply collected data on a ~60,000 battleship games and then I used Apple's CreateML to train a model. Unfortunantely I had not realized their was a bug in the ship placement causing ships to only be placed vertically. After learning alot about tensorflow and the many aspects of Machine Learning I took another stab at the project.
## The Model
### Input Pipeline
The board is split into 6 channels and a 10 by 10 grid (6,10,10). Values in channel 0 are 0.0 or 1.0. 1 represents a square that has been shot at and was a miss. Values in channels 1 through 5 correspond to each of the 5 ships and values are either -1.0, 0.0 or 1.0. -1.0 represents a ships has been sunk. 1.0 represents a hit but not a sunk ship. 
### The Model
The model uses convolutions to intially identify patterns in the data. The convolutions are then concatenated and passed through a 2d (fully connected) locally connected layer with sigmoid activation and then flattened and passed to output. The model is expected to have high confidence in multiple squares and is trained with multi-labels thus sigmoid is used over softmax. I use a locally connected layer here because it was *slightly* faster when using Accelerated Linear Algebra XLA. I chose to use 'selu' activation instead of 'relu' to prevent some weights from dying at the expense of longer training times. I also experimented with using L1 and L2 constraints. L1 is used in the convolutions because the data in some adjacent squares may not have an effect on prediction. L2 is used is used in the LC layer because all convolutions should have an effect on each each prediction however the more important a filter the greater of an impact it shoudl have thus the regularization. 
